{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJK-gYbKVyCh",
        "outputId": "26aac2e4-a644-4653-d341-38353393ce91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.7/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat) (0.13.0)\n"
          ]
        }
      ],
      "source": [
        "pip install textstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bmhUZZnPV-7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656142e4-ba60-4ff5-95c8-00701c2861d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y5QY_DgcWE-T"
      },
      "outputs": [],
      "source": [
        "import pandas as panda\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn\n",
        "from textstat.textstat import *\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import warnings\n",
        "import tensorflow\n",
        "import io\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hH1g_-Q3WJRH",
        "outputId": "94df2603-493b-4bdf-9706-c6fd82c7b6c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id keyword location  \\\n",
              "0         1     NaN      NaN   \n",
              "1         4     NaN      NaN   \n",
              "2         5     NaN      NaN   \n",
              "3         6     NaN      NaN   \n",
              "4         7     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "7608  10869     NaN      NaN   \n",
              "7609  10870     NaN      NaN   \n",
              "7610  10871     NaN      NaN   \n",
              "7611  10872     NaN      NaN   \n",
              "7612  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
              "1                Forest fire near La Ronge Sask. Canada       1  \n",
              "2     All residents asked to 'shelter in place' are ...       1  \n",
              "3     13,000 people receive #wildfires evacuation or...       1  \n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
              "...                                                 ...     ...  \n",
              "7608  Two giant cranes holding a bridge collapse int...       1  \n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
              "7611  Police investigating after an e-bike collided ...       1  \n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-301b35fe-b271-46b6-b26b-62fb3a6a5a36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-301b35fe-b271-46b6-b26b-62fb3a6a5a36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-301b35fe-b271-46b6-b26b-62fb3a6a5a36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-301b35fe-b271-46b6-b26b-62fb3a6a5a36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset = panda.read_csv('/content/train.csv')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "okVARrPDgtdN",
        "outputId": "218ff0f1-f8e9-436a-89f7-0af0255747c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target\n",
              "0     Our Deeds are the Reason of this #earthquake M...       1\n",
              "1                Forest fire near La Ronge Sask. Canada       1\n",
              "2     All residents asked to 'shelter in place' are ...       1\n",
              "3     13,000 people receive #wildfires evacuation or...       1\n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
              "...                                                 ...     ...\n",
              "7608  Two giant cranes holding a bridge collapse int...       1\n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
              "7611  Police investigating after an e-bike collided ...       1\n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
              "\n",
              "[7613 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bec3dd35-442d-4000-9fd3-f4e7128e19cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec3dd35-442d-4000-9fd3-f4e7128e19cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bec3dd35-442d-4000-9fd3-f4e7128e19cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bec3dd35-442d-4000-9fd3-f4e7128e19cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset.drop(['id', 'keyword', 'location'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ClGS3ZWXf9",
        "outputId": "52cbda5a-6d02-4ed7-a67a-d887782500f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gkjTN5GWfG9",
        "outputId": "9380e60a-e6d2-45dc-975d-0d49e9ebc68e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Our Deeds are the Reason of this #earthquake M...\n",
              "1               Forest fire near La Ronge Sask. Canada\n",
              "2    All residents asked to 'shelter in place' are ...\n",
              "3    13,000 people receive #wildfires evacuation or...\n",
              "4    Just got sent this photo from Ruby #Alaska as ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# collecting only the tweets from the csv file into a variable name tweet\n",
        "tweet=dataset.text\n",
        "tweet.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = pd.panda.read_csv('/content/test.csv')\n",
        "test_dataset"
      ],
      "metadata": {
        "id": "pLtjbvlhywTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.drop(['id', 'keyword', 'location'], axis = 1)"
      ],
      "metadata": {
        "id": "Zh3dXUR7zAhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFU5ftVliADE",
        "outputId": "0ced81a1-b66a-4c4b-8b71-1ed43d62f9fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  Our Deeds are the Reason of this #earthquake M...   \n",
            "1             Forest fire near La Ronge Sask. Canada   \n",
            "2  All residents asked to 'shelter in place' are ...   \n",
            "3  13,000 people receive #wildfires evacuation or...   \n",
            "4  Just got sent this photo from Ruby #Alaska as ...   \n",
            "5  #RockyFire Update => California Hwy. 20 closed...   \n",
            "6  #flood #disaster Heavy rain causes flash flood...   \n",
            "7  I'm on top of the hill and I can see a fire in...   \n",
            "8  There's an emergency evacuation happening now ...   \n",
            "9  I'm afraid that the tornado is coming to our a...   \n",
            "\n",
            "                                    processed_tweets  \n",
            "0  our deeds are the reason of this earthquake ma...  \n",
            "1              forest fire near la ronge sask canada  \n",
            "2  all residents asked to shelter in place are be...  \n",
            "3  people receive wildfires evacuation orders in ...  \n",
            "4  just got sent this photo from ruby alaska as s...  \n",
            "5  rockyfire update california hwy closed in both...  \n",
            "6  flood disaster heavy rain causes flash floodin...  \n",
            "7  i m on top of the hill and i can see a fire in...  \n",
            "8  there s an emergency evacuation happening now ...  \n",
            "9  i m afraid that the tornado is coming to our area  \n"
          ]
        }
      ],
      "source": [
        "## 1. Removal of punctuation and capitlization\n",
        "## 2. Tokenizing\n",
        "## 3. Removal of stopwords\n",
        "## 4. Stemming\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "#extending the stopwords to include other words used in twitter such as retweet(rt) etc.\n",
        "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
        "stopwords.extend(other_exclusions)\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "lem = WordNetLemmatizer()\n",
        "#stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(tweet):  \n",
        "    \n",
        "    # removal of extra spaces\n",
        "    regex_pat = re.compile(r'\\s+')\n",
        "    tweet_space = tweet.str.replace(regex_pat, ' ')\n",
        "\n",
        "    # removal of @name[mention]\n",
        "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
        "    tweet_name = tweet_space.str.replace(regex_pat, '')\n",
        "\n",
        "    ###### \"added this part later, should be removed\"  removal of rt[mention]\n",
        "    regex_pat = re.compile(r'RT')\n",
        "    tweet_name = tweet_name.str.replace(regex_pat, '')\n",
        "\n",
        "    # removal of links[https://abc.com]\n",
        "    giant_url_regex =  re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    tweets = tweet_name.str.replace(giant_url_regex, '')\n",
        "    \n",
        "    # removal of punctuations and numbers\n",
        "    punc_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \")\n",
        "    # remove whitespace with a single space\n",
        "    newtweet=punc_remove.str.replace(r'\\s+', ' ')\n",
        "    # remove leading and trailing whitespace\n",
        "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
        "    # replace normal numbers with numbr\n",
        "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
        "\n",
        "    # removal of capitalization\n",
        "    tweet_lower = newtweet.str.lower()\n",
        "    \n",
        "    # tokenizing\n",
        "    tokenized_tweet = tweet_lower.astype(str).str.split()\n",
        "    \n",
        "    # removal of stopwords\n",
        "    #tokenized_tweet=  tokenized_tweet.apply(lambda x: [item for item in x if item not in stopwords])\n",
        "    \n",
        "    # stemming of the tweets (remove -ing, -ly, ...)\n",
        "    #tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
        "\n",
        "    ## Lemmatisation (convert the word into root word)\n",
        "    #tokenized_tweet = tokenized_tweet.apply(lambda x: [lem.lemmatize(i) for i in x])\n",
        "    \n",
        "    for i in range(len(tokenized_tweet)):\n",
        "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "        tweets_p = tokenized_tweet\n",
        "    \n",
        "    return tweets_p\n",
        "\n",
        "processed_tweets = preprocess(tweet)   \n",
        "\n",
        "dataset['processed_tweets'] = processed_tweets\n",
        "print(dataset[[\"text\",\"processed_tweets\"]].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-pchZMvWWjNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80d6a73-fbf9-4f7a-abbd-ae2830a8a648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.48.1)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.26.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-kjc7uPWW3bs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0axD690HW9AY"
      },
      "outputs": [],
      "source": [
        "#X = df_balanced.drop(df_balanced.columns[[0,1,2,3,4,5,6,7]], axis=1)\n",
        "#y = df_balanced.drop(df_balanced.columns[[0,1,2,3,5,6,7,8]], axis=1) \n",
        "X = dataset['text']\n",
        "y = dataset['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-oQtRkHXGU1",
        "outputId": "0c23c0a5-f18a-4bc2-da92-6ec65f7b4d24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "y = np.asarray(y).astype(np.float32)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fz8xNIIAXJ09"
      },
      "outputs": [],
      "source": [
        "X = X.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBGjRaOHZg7a",
        "outputId": "be6f2f3d-9d70-4476-eaa9-b0fe223c0d71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
              "       'Forest fire near La Ronge Sask. Canada',\n",
              "       \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n",
              "       ...,\n",
              "       'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ',\n",
              "       'Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.',\n",
              "       'The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(X).astype('str')"
      ],
      "metadata": {
        "id": "iQ4H_nq2OESh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HMd2HIqVXzhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ffacc2-009a-4146-c1a5-0f86273ad9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ],
      "source": [
        "# Bert downlaod/import\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N3coP0TDX9EE"
      },
      "outputs": [],
      "source": [
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IWKZMmAYYZZW"
      },
      "outputs": [],
      "source": [
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "final_output = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a9eYOFALYjqe"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[text_input], outputs = [final_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65pzzfNTYpfM",
        "outputId": "16f782a1-947e-4be3-b1d9-ac938aa0c610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer[0][0]',            \n",
            "                                None, 768),                       'keras_layer[0][1]',            \n",
            "                                 'default': (None,                'keras_layer[0][2]']            \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768)}                                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aouSqhHPYsFO"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        " loss='binary_crossentropy',\n",
        " metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihY76DMMY9-q",
        "outputId": "0a26606b-ea00-42bf-8f3e-820077fbac80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "238/238 [==============================] - 77s 322ms/step - loss: 0.6068 - accuracy: 0.6756 - precision: 0.6411 - recall: 0.5564\n",
            "Epoch 2/10\n",
            "238/238 [==============================] - 77s 322ms/step - loss: 0.5811 - accuracy: 0.7063 - precision: 0.6813 - recall: 0.5946\n",
            "Epoch 3/10\n",
            "238/238 [==============================] - 78s 326ms/step - loss: 0.5665 - accuracy: 0.7214 - precision: 0.6972 - recall: 0.6215\n",
            "Epoch 4/10\n",
            "238/238 [==============================] - 76s 319ms/step - loss: 0.5615 - accuracy: 0.7234 - precision: 0.7007 - recall: 0.6218\n",
            "Epoch 5/10\n",
            "238/238 [==============================] - 77s 324ms/step - loss: 0.5485 - accuracy: 0.7319 - precision: 0.7125 - recall: 0.6304\n",
            "Epoch 6/10\n",
            "238/238 [==============================] - 77s 322ms/step - loss: 0.5427 - accuracy: 0.7370 - precision: 0.7193 - recall: 0.6362\n",
            "Epoch 7/10\n",
            "238/238 [==============================] - 79s 330ms/step - loss: 0.5347 - accuracy: 0.7471 - precision: 0.7355 - recall: 0.6426\n",
            "Epoch 8/10\n",
            "238/238 [==============================] - 79s 331ms/step - loss: 0.5323 - accuracy: 0.7452 - precision: 0.7292 - recall: 0.6472\n",
            "Epoch 9/10\n",
            "238/238 [==============================] - 81s 339ms/step - loss: 0.5306 - accuracy: 0.7461 - precision: 0.7325 - recall: 0.6445\n",
            "Epoch 10/10\n",
            "238/238 [==============================] - 80s 338ms/step - loss: 0.5276 - accuracy: 0.7491 - precision: 0.7360 - recall: 0.6487\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30e361c890>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.fit(X, y, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/tweet_classification_model.h5') "
      ],
      "metadata": {
        "id": "_8k0hvU17dtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVoM_rpIJrEK",
        "outputId": "324ec653-224a-42e3-919a-5bc485eece1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.11920381337404251\n",
            "Test accuracy: 0.9620023965835571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "metadata": {
        "id": "h4CLLchvtZnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1176ef6c-9144-44ba-9fe0-bd067b7ea64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OIZqiycWZlK",
        "outputId": "1b0770a3-f99d-4847-f6f6-4bb2a164e8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "metadata": {
        "id": "GL-9oB_pormA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}